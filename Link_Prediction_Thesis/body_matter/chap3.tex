\chapter{Πειράματα και Αποτελέσματα}

Στο κεφάλαιο αυτό θα αναλυθούν οι ακριβείς συνθήκες κάτω από τις οποίες διεξήχθησαν τα πειράματα,
καθώς και τα αποτελέσματα αυτών. Δόθηκε ιδιαίτερη σημασία στην ομοιότητα των συνθηκών, ώστε όλα
τα πειράματα να εκτελούνται κατά το δυνατόν στις ίδιες συνθήκες. Φυσικά, κάθε υλοποίηση και κάθε
σύνολο δεδομένων παρουσιάζει και κάποιες ιδιαιτερότητες, όπως για παράδειγμα οι διαφορετικές 
παράμετροι, οι τεχνικές διαφορές σε θέματα σχεδιασμού, κ.τ.λ. Επίσης, σε κάθε επαναλαμβανόμενο πείραμα
και ειδικότερα για τον διαχωρισμό των δεδομένων, τα υποσύνολα είναι διαφορετικά κάθε φορά, αφού
οι διαχωρισμοί γίνονται με παραμέτρους αναλογίας, ενώ η συλλογή των ακριβών παρατηρήσεων που
επιλέγονται κάθε φορά για κάποιο υποσύνολο δεδομένων γίνεται με τυχαίο τρόπο. Αυτές οι επιλογές έγιναν
ώστε να διατηρείται κατα το δυνατόν η αντικειμενικότητα ανα τα πειράματα και τις επαναλήψεις. Συνεπώς,
σε κάθε επανάληψη τα αποτελέσματα διαφέρουν κατα ένα μικρό ποσοστό.

\section{Πειράματα}

\subsection{\en{Node2Vec}}

Όπως ήδη αναλύθηκε, τα δεδομένα διαχωρίστηκαν ως εξής: Από τον αρχικό γράφο, αποκόπηκε το \(10\%\)
των ακμών, και μαζί με ισάριθμες τυχαίες ψευδείς ακμές, συγκροτείται το σύνολο δεδομένων ελέγχου.
Από τις εναπομείναντες ακμές, συγκροτήθηκε ο γράφος ελέγχου. Από τον γράφο ελέγχου, αποκόπηκε
ξανά το \(10\%\) των ακμών και μαζί με ισάριθμες ψευδείς ακμές συγκροτήθηκε το σύνολο δεδομένων 
εκπαίδευσης. Από τις ακμές που απέμεναν, συγκροτήθηκε ο γράφος εκπαίδευσης. Τέλος, το σύνολο
δεδομένων εκπαίδευσης, διαχωρίστηκε κατα αναλογία \(75/25\) σε σύνολο δεδομένων για την εκπαίδευση
και επικύρωση των ταξινομητών αντίστοιχα, κατα το στάδιο της επιλογής του βέλτιστου τελεστή 
εξαγωγής ακμών.

Κατα την εξαγωγή τυχαίων περιπάτων, χρησιμοποιήθηκαν οι εξής παράμετροι:

\begin{itemize}
    \item \(p = 1\)
    \item \(q = 1\)
    \item Μήκος Περιπάτου \( = 80\) (κόμβοι)
    \item Αριθμός Περιπάτων \( = 10\)
\end{itemize}

Κατα την εξαγωγή αναπαραστάσεων σύμφωνα με το μοντέλο \en{Word2Vec} χρησιμοποιήθηκαν οι εξής
παράμετροι:

\begin{itemize}
    \item Διαστάσεις αναπαραστάσεων \(= 128\)
    \item Μέγεθος Παραθύρου \(= 10\) (κόμβοι)
    \item Αριθμός επαναλήψεων \(= 1\)
\end{itemize}

Κατά τη δημιουργία και την εκπαίδευση ταξινομητών Λογαριθμικής Παλινδόμησης με Διασταυρωμένη
Επικύρωση (\en{Logistic Regression with Cross-Validation}) \cite{scikit-learn} χρησιμοποιήθηκαν
οι εξής παράμετροι:

\begin{itemize}
    \item \(Cs = 10\)
    \item \(cv = 10\)
    \item Μετρική Επικύρωσης = \en{ROC\_AUC}
    \item Μέγιστος αριθμός επαναλήψεων \(= 2000\)
\end{itemize}

\subsection{\en{CTDNE}}

Στην δεύτερη υλοποίηση τα δεδομένα διαχωρίστηκαν κατα τον ίδιο ακριβώς τρόπο, ενώ κατα την εξαγωγή
χρονικά ορθών (\en{temporal}) τυχαίων περιπάτων χρησιμοποιήθηκαν οι εξής παράμετροι:

\begin{itemize}
    \item Μέγεθος παραθύρου περιβάλλοντος \(= 2\)
    \item Μέγιστο μήκος περιπάτου \(= 80\) (κόμβοι)
    \item Αριθμός παραθύρων περιβάλλοντος όπως προκύπτει από την εξίσωση (\ref{2.19})
    \item Εκθετική Πόλωση επιλογής ακμών
\end{itemize}

Κατα την εξαγωγή αναπαραστάσεων σύμφωνα με το μοντέλο \en{Word2Vec} χρησιμοποιήθηκαν οι εξής
παράμετροι:

\begin{itemize}
    \item Διαστάσεις αναπαραστάσεων \(= 128\)
    \item Μέγεθος Παραθύρου \(= 2\) (κόμβοι)
    \item Αριθμός επαναλήψεων \(= 1\)
\end{itemize}

Η επιλογή των τελεστών και του ταξινομητή έγινε με ακριβώς τις ίδιες παραμέτρους όπως και στην 
υλοποίηση με \en{Node2Vec}.

\subsection{\en{GraphSAGE}}

Στην υλοποίηση αυτή τα δεδομένα διαχωρίστηκαν κατα τα γνωστά σε γράφο εκπαίδευσης και ελέγχου,
καθώς και σχηματίστηκαν και τα δεδομένα εκπαίδευσης και ελέγχου με αληθείς και ψευδείς ακμές.
Όπως και προηγουμένως, τηρήθηκαν οι ίδιες αναλογίες, όπου από τον αρχικό γράφο χρησιμοποιήθηκε
το \(10\%\) των αληθών ακμών και ισάριθμες ψευδείς ακμές για το σχηματισμό των δεδομένων ελέγχου
και με τις εναπομείναντες ακμές δημιουργήθηκε ο γράφος ελέγχου. Εν συνεχεία, από τον γράφο ελέγχου
με την ίδια ακριβώς λογική σχηματίστηκαν τα δεδομένα και ο γράφος εκπαίδευσης.

Για τη γεννήτρια ακμών το μέγεθος των δεσμών ορίστηκε ίσο με \(20\) ακμές. Δειγματοληπτούνται
για κάθε κόμβο 20 πρωτεύοντες (άμεσοι) γείτονες και 10 δευτερεύοντες γείτονες. Κάθε στρώμα του
μοντέλου έχει μέγεθος 20, και χρησιμοποιήθηκε \en{dropout rate = \(0.3\)} \footnote{Το 
\en{dropout rate} αποτελεί μια τεχνική βελτίωσης της απόδοσης ενός μοντέλου. Κατα τη διαδικασία
εκπαίδευσης ενός νευρωνικού δικτύου αγνοούνται νευρώνες τυχαία, κάτι που βοηθάει κυρίως στην
αποφυγή του φαινομένου της υπερεκπαίδευσης \cite{DataMining}.}. Όσο για τον τελεστή δημιουργίας
αναπαραστάσεων ακμών από τις αναπαραστάσεις κόμβων, επιλέχθηκε να είναι ο τελεστής του εσωτερικού
γινομένου ή αλλιώς ο τελεστής \en{Hadamard}.

Κατα τη δημιουργία του τελικού μοντέλου \en{keras}, χρησιμοποιήθηκε ο βελτιστοποιητής 
(\en{optimizer}) \en{Adam} με παράμετρο \(lr = 1e-3\) (\en{tensorflow.keras.optimizers.Adam()}). 
Για συνάρτηση απώλειας (\en{loss function}) χρησιμοποιήθηκε η συνάρτηση δυαδικής εγκάρσιας
εντροπίας (\en{binary crossentropy}) (\en{tensorflow.keras.losses.binary\_crossentropy}). Τέλος,
το μοντέλο εκπαιδεύτηκε για 20 εποχές.

\section{Αποτελέσματα}

Στην παράγραφο αυτή παρουσιάζονται τα αποτελέσματα των πειραμάτων. Κάθε σύνολο δεδομένων 
παρουσιάζεται ξεχωριστά ενώ οι διαφορετικές τεχνικες συγκρίνονται μεταξύ τους για κάθε σύνολο
δεδομένων. Τα πειράματα διεξήχθησαν όπως περιγράφηκε παραπάνω και οι μετρικές απόδοσης μετρώνται 
πάνω στο  σύνολο δεδομένων ελέγχου. Να σημειωθεί πως για την υλοποίηση με \en{CTDNE} τα πειράματα στα οποία
συμπεριλήφθηκε η χρονική παράμετρος  αναφέρονται ως "\en{temporal}" ενώ στη δοκιμή χωρίς τη χρονική
παράμετρο δίνεται το χαρακτηριστικό "\en{static}".

\subsection{\en{CORA Dataset}}

Στον πίνακα \ref{table4.1} φαίνονται οι τιμές των μετρικών πάνω στα δεδομένα ελέγχου.
Παρατηρώντας τις μετρικές των αποτελεσμάτων, φαίνεται πως βάσει μετρικής Ακρίβειας, \en{Precision, AUC} 
και \en{F1} 
καλύτερη απόδοση έχει η τεχνική \en{Node2Vec}. Δεύτερη σε απόδοση είναι η \en{GraphSAGE}, η οποία
φαίνεται να αποδίδει πολύ καλα βάσει μετρικής \en{AUC}. Tρίτη είναι η 
\en{CTDNE}, κάτι που είναι
αναμενόμενο, αφού έχει σχεδιαστεί για λειτουργία με δεδομένα που συμπεριλαμβάνουν τη χρονική
παράμετρο, κάτι που το συγκεκριμένο σύνολο δεδομένων δεν προσφέρει. Τέλος, θα πρέπει κυρίως να τονιστεί η απόδοση της
\en{Node2Vec} με παραμέτρους \en{CTDNE}, η οποία ξεπέρασε σε απόδοση τις υπόλοιπες τεχνικές σύμφωνα με τη μετρική \en{Recall}.

\begin{table}[!tb]
	\centering
	\caption{Πίνακας μετρικών απόδοσης για το σύνολο δεδομένων \en{CORA}}
	\small
	\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{| c || c | c | c | c | c |}
		\hline               
		 \textbf{Υλοποίηση} & \textbf{\en{Accuracy}} & \textbf{\en{Precision}} &
		 \textbf{\en{Recall}} & \textbf{\en{AUC}} &  \textbf{\en{F1 Score}} \\
		\hline
		    \en{Node2Vec} & 0.8235 & \textbf{0.8350} & 0.8065 & 
		                                        0.8614 & \textbf{0.8204}  \\
			\en{CTDNE Temporal} & 0.7419 & 0.7457 & 0.7343 & 0.8416 & 0.7400  \\
			\en{CTDNE Static} & 0.4877 & 0.4932 & \textbf{0.8899} & 0.7232 & 0.6346  \\
			\en{GraphSAGE} & \textbf{0.8837} & 0.5016 & 0.4425 & \textbf{0.8898} & 0.4671  \\
		\hline
	\end{tabular}
	\label{table4.1}
\end{table}
	
\subsection{\en{Bitcoin-OTC Dataset}}

Παρατηρείται πως στο συγκεκριμένο σύνολο δεδομένων βάσει όλων των μετρικών, τη βέλτιστη 
απόδοση έχει η τεχνική \en{CTDNE}, κάτι που είναι αναμενόμενο, αφού σχεδιάστηκε για να λειτουργεί
βέλτιστα πάνω σε δεδομένα με τη χρονική παράμετρο παρεχόμενη, κάτι που ισχύει στο συγκεκριμένο σύνολο
δεδομένων. Πάλι όμως βάσει κριτηρίου \en{AUC}, τη πολύ καλή απόδοση έχει η τεχνική \en{GraphSAGE}. Να
επαναλάβουμε σε αυτό το σημείο πως η τεχνική αυτή χρησιμοποιήθηκε σε συνδυασμό με τη \en{Node2Vec}. Η 
τελευταία χρησιμοποιήθηκε για την κατασκευή χαρακτηριστικών κόμβων, αφού στο αρχικό σύνολο δεδομένων
δεν υπήρχαν διαθέσιμα, ενώ είναι απαραίτητα για την λειτουργία της τεχνικής αυτής.


\begin{table}[!tb]
	\centering
	\caption{Πίνακας μετρικών απόδοσης για το σύνολο δεδομένων \en{Bitcoin-OTC}}
	\small
	\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{| c || c | c | c | c | c |}
		\hline               
		 \textbf{Υλοποίηση} & \textbf{\en{Accuracy}} & \textbf{\en{Precision}} &
		 \textbf{\en{Recall}} & \textbf{\en{AUC}} &  \textbf{\en{F1 Score}} \\
		\hline
		    \en{Node2Vec} & 0.6024 & 0.5840 & 0.7120 & 0.6629 & 0.6416  \\
			\en{CTDNE Temporal} & \textbf{0.8350} & \textbf{0.8475} & \textbf{0.8171} 
			                    & \textbf{0.8973} & \textbf{0.8320}  \\
			\en{CTDNE Static} & 0.4999 & 0.2500 & 0.0004 & 0.3252 & 0.0009  \\
			\en{GraphSAGE} & 0.7527 & 0.5008 & 0.4669 & 0.8817 & 0.4827  \\
		\hline
	\end{tabular}
	\label{table4.2}
\end{table}

