\chapter{Μεθοδολογία}

Στο κεφάλαιο αυτό θα αναλυθεί η μεθοδολογία που ακολουθήθηκε για την διεκπεραίωση της εργασίας
αυτής, καθώς και ο λόγος που έγιναν οι συγκεκριμένες επιλογές, τόσο ως προς τις τεχνικές
όσο και τα δεδομένα. Αρχικά θα αναλυθούν τα σύνολα δεδομένων που επιλέχθηκαν, και έπειτα
θα αναλυθεί ο τρόπος δόμησης κάθε τεχνικής.

\section{Δεδομένα}

Για την εργασία αυτή επιλέχθηκαν δύο σύνολα δεδομένων με διαφορετικές ιδιότητες το καθένα. Πρώτο
επιλέχθηκε το \en{CORA Dataset} (μτφ. Σύνολο Δεδομένων) \cite{sen2008collective} και δεύτερο το 
\en{Bitcoin OTC (trust weighted signed network) Dataset} \cite{kumar2016edge} \cite{kumar2018rev2}.

\subsection{\en{CORA dataset}}

To \en{CORA Dataset} δημιουργήθηκε στα πλαίσια μιας προσπάθειας δημιουργίας ενός συνόλου
δεδομένων κατάλληλο για εξέλιξη τεχνικών ταξινόμησης με χρήση μηχανικής μάθησης
\cite{sen2008collective}. Το αρχικό σύνολο δεδομένων αποτελείται από ένα σύνολο 2708
επιστημονικών δημοσιεύσεων, που αποτελούν τους κόμβους. Οι δημοσιεύσεις/κόμβοι είναι κατηγοριοποιημένοι
σε μία από 7 κλάσεις σχετικά με το αντικείμενο τους:

\begin{itemize}
    \item Με βάση την υπόθεση (\en{Case Based})
    \item Γενετικοί Αλγόριθμοι (\en{Genetic Algorithms})
    \item Νευρωνικά Δίκτυα (\en{Neural Networks})
    \item Πιθανοτικές Μέθοδοι (\en{Probabilistic Methods})
    \item Επιβραβευόμενη Μάθηση (\en{Reinforcement Learning})
    \item Εκμάθηση Κανόνων (\en{Rule Learning})
    \item Θεωρία (\en{Theory})
\end{itemize}

Κάθε επιστημονική δημοσίευση (κόμβο) συνοδεύεται από ένα σύνολο χαρακτηριστικών (\en{Node 
attributes}). Κατά το σχεδιασμό του συνόλου δεδομένων, σχηματίστηκε ένα λεξικό με λέξεις που
υπάρχουν στις δημοσιεύσεις και χαρακτηρίζουν το περιεχόμενό τους. Αφαιρέθηκαν δηλαδή αντωνυμίες,
άρθρα, κ.λπ. Τελικά σχηματίστικε ένα σύνολο 1433 μοναδικών λέξεων. Κάθε κόμβος χαρακτηρίζεται
από ένα διάνυσμα 1433 θέσεων, όπου κάθε θέση συμπληρώνεται με "0" ή "1" ανάλογα με το εάν
υπάρχει στη δημοσίευση η λέξη του λεξικού στην οποία αντιστοιχεί η συγκεκριμένη θέση. Αυτά 
τα δεδομένα είναι αποθηκευμένα σε μορφή \(1 + 1433 + 1 = 1435\) στηλών για 2780 γραμμές
ως εξής:

\begin{equation*}
    <paper\_id><word\_attributes><class\_label> 
\end{equation*}

Οι επιστημονικές δημοσιεύσεις συνδέονται μεταξύ τους, ανάλογα με το ποιες έχουν αναφορές σε
ποιες, και κάθε δημοσίευση αναφέρεται από τουλάχιστον μία άλλη. Συνολικά υπάρχουν 5429 
συνδέσεις. Τα δεδομένα των συνδέσεων είναι αποθηκευμένα σε μορφή 2 στηλών για 5429 γραμμές
ως εξής:

\begin{equation*}
    <cited\_paper><citing\_paper>
\end{equation*}

δηλαδή η επιστημονική δημοσίευση στη δεύτερη στήλη κάνει αναφορά στην επιστημονική δημοσίευση
που βρίσκεται στην πρώτη στήλη. Το συγκεκριμένο σύνολο δεδομένων επιλέχθηκε επειδή αφ' ενός 
αντιπροσωπεύει μια εικόνα της επιστημονικής κοινότητας αλλά κυρίως επειδή εμπεριέχει πολύ 
έντονα το στοιχείο των χαρακτηριστικών, κάτι το οποίο θα δώσει έμφαση στις διαφορές και στο 
αποτέλεσμα των τεχνικών πρόβλεψης που χρησιμοποιούν τα χαρακτηριστικά των κόμβων στον
αλγόριθμό τους. Το σύνολο δεδομένων αυτό χρησιμοποιήθηκε αυτούσιο χωρίς κάποια μετατροπή.

\subsection{\en{Bitcoin OTC trust weighted signed network dataset}} \label{BTCDataset}

Το δεύτερο σύνολο δεδομένων που επιλέχθηκε αναπτύχθηκε στα πλαίσια μιας προσπάθειας πρόβλεψης
της αξιοπιστίας χρηστών ενός δικτύου \cite{kumar2016edge} και ανανεώθηκε στα πλαίσια μιας 
προσπάθειας ανίχνευσης ψευδών χρηστών στις πλατφόρμες βαθμολόγησης \cite{kumar2018rev2}.
Το δίκτυο αντιπροσωπεύει τις σχέσεις εμπιστοσύνης μεταξύ των χρηστών σε μια πλατφόρμα 
συναλλαγών με \en{bitcoin}, ονόματι \en{Bitcoin OTC}. Αποτελείται από ένα σύνολο 5881 χρηστών
(κόμβων) και 35592 συνδέσεων (ακμών). Στην πλατφόρμα αυτή, οι χρήστες δύνανται
να βαθμολογήσουν ως προς την αξιοπιστία άλλους χρήστες σε μια κλιμάκα ακέραιων αριθμών από το   -10 έως το 10  που δεν περιλαμβάνει το 0 , κάτι που δίνει και την ιδιότητα του προσημασμένου στο δίκτυο, και την έννοια της
αξιολόγησης στην ακμή. Επίσης καταγράφεται η
χρονική στιγμή της αξιολόγησης, κάτι το οποίο είναι ένα απαραίτητο στοιχείο για την λειτουργία
των αλγορίθμων που εκμεταλλεύονται τη χρονική παράμετρο της δημιουργίας των ακμών και την
πρόβλεψή τους. Στους εν λόγω αλγορίθμους, όπως ο \en{CTDNE}
(βλέπε Ενότητα \ref{CTDNE}) η χρονική στιγμή (\en{timestamp}) της αξιολόγησης χρησιμοποιείται ως βάρος
ακμής, ενώ στους συμβατικούς, όπως ο \en{Node2Vec} (Ενότητα \ref{n2v}) και ο \en{GraphSAGE} 
(Ενότητα \ref{gsage}) χρησιμοποιείται ως βάρος ακμής η βαθμολογία. 

Για την ορθή λειτουργία των αλγορίθμων έγινε μια μετατροπή στη βαθμολογία, αφού ήταν αδύνατο 
να επεξεργαστούν αρνητικά βάρη. Έτσι, η βαθμολογία
κανονικοποιήθηκε έτσι ώστε να ανήκει στο \( [0,1]\) με το "0" να είναι η χειρότερη και το "1" η καλύτερη
βαθμολογία.

Το δίκτυο είναι αποθηκευμένο σε μορφή 4 στηλών για 35592 γραμμές ως εξής: 

\begin{equation*}
    <source><target><rating><time>
\end{equation*}

όπου \begin{itemize}
    \item \en{Source}: o βαθμολογητής χρήστης
    \item \en{Target}: ο βαθμολογούμενος χρήστης
    \item \en{Rating}: η βαθμολογία
    \item \en{Time}: η χρονική στιγμή που καταχωρήθηκε η βαθμολογία σε δευτερόλεπτα από τη 
    στιγμή \en{Epoch} \footnote{Η χρονική στιγμή \en{Epoch} στα υπολογιστικά συστήματα
    θεωρείται η χρονική στιγμή του παρελθόντος από την οποία μετρώνται οι χρόνοι,
    οι ημερομηνίες, κ.α. Στα υπολογιστικά συστήματα \en{Unix} ως χρονική στιγμή
    \en{epoch} θεωρείται η 1/1/1970.}
\end{itemize}

\section{Υλοποιήσεις}

Στην παράγραφο αυτή θα αναλυθεί αρχικά η γενική δομή των λύσεων, και στη συνέχεια 
ο τρόπος δόμησης κάθε υλοποίησης.

Η γενική μορφή της λύσεις έχει τρία στάδια:

\begin{itemize}
    \item Εισαγωγή και προετοιμασία δεδομένων και διαχωρισμός σε σύνολα εκπαίδευσης και ελέγχου
    \item Εξαγωγή αναπαραστάσεων των ακμών και εύρεση βέλτιστου τελεστή
    \item Χρήση ενός ταξινομητή για πρόβλεψη και επαλήθευση αποτελεσμάτων
\end{itemize}


\subsection{Υλοποίηση με \en{Node2Vec}}

\subsubsection{Εισαγωγή και διαχωρισμός δεδομένων} \label{n2v_data}

Αρχικά τα δεδομένα διαβάζονται από το αντίστοιχο αρχείο και δημιουργείται μια δομή γράφου με
χρήση της βιβλιοθήκης \en{NetworkX} \cite{Networkx}. Από τη δομή αυτή δημιουργείται ένας
πίνακας δύο ή τριών στηλών, ανάλογα με το χρησιμοποιούμενο σύνολο δεδομένων, όπου κάθε γραμμή έχει τη μορφή \(\{"source", "target", "weight"\}\).
Όπως είναι προφανές, η τρίτη στήλη υπάρχει μόνο εάν ο γράφος έχει και βάρη ακμών. Διαφορετικά,
οι \en{constructors} των δομών γραφών ορίζουν αυτόματα όλα τα βάρη των ακμών ίσα με τη μονάδα.
Για την προαναφερθείσα λειτουργία χρησιμοποιείται ειδική συνάρτηση που παίρνει σαν ορίσματα
το όνομα του αρχείου που περιέχει την λίστα ακμών και μια δυαδική μεταβλητή που σηματοδοτεί
την ύπαρξη ή όχι βαρών στη λίστα αυτή, ενώ επιστρέφει μια μεταβλητή τύπου \en{pandas DataFrame}
\cite{mckinney-proc-scipy-2010} με δύο ή τρείς στήλες, όπως περιγράφηκε ήδη.

Στη συνέχεια, από την επιστρεφόμενη λίστα δημιουργείται ένας γράφος με χρήση του \en{constructor}
της βιβλιοθήκης \en{StellarGraph} \cite{StellarGraph}. Γενικά η χρήση της βιβλιοθήκης αυτής είναι
εκτεταμένη σε όλες τις υλοποιήσεις, αφού προσφέρει τα κατάλληλα εργαλεία για όλες τις απαραίτητες
διεργασίες. Για το διαχωρισμό των δεδομένων ακολουθήθηκε η εξής στρατηγική: Τα δεδομένα 
χωρίστηκαν σε 2 γράφους και 2 λίστες ακμών με ετικέτες. Από τον αρχικό γράφο, \(G\), αφαιρούνται
ορισμένες ακμές, συγκεκριμένα το \(10\%\) των ακμών του \(G\), και μαζί με ισάριθμες ψευδείς
ακμές, δηλαδή ακμές που δεν υπάρχουν στον γράφο συγκεντρώνονται σε μια λίστα, 
ονόματι \en{examples\_test}, μαζί με τις ετικέτες που χαρακτηρίζουν εάν πρόκειται για ψευδή ή
αληθή ακμή, ονόματι \en{labels\_test}. Από τις εναπομείναντες ακμές, δημιουργείται ο γράφος
ελέγχου, \en{G\_test}. Η λίστα \en{examples\_test} θα χρησιμοποιηθεί για την επικύρωση του 
μοντέλου στο τέλος της διαδικασίας, ενώ ο γράφος \en{G\_test} θα χρησιμοποιηθεί για την εξαγωγή
αναπαραστάσεων ακμών του αρχικού γράφου με τις βέλτιστες παραμέτρους. Ο τρόπος εξαγωγής των 
βέλτιστων παραμέτρων θα περιγραφεί στη συνέχεια. 

Η ίδια διαδικασία
επαναλαμβάνεται μία φορά ακόμη, αυτή τη φορά με αρχικό γράφο τον \en{G\_test} και εξάγονται ο
γράφος \en{G\_train} και οι λίστες \en{examples} και \en{labels}. Ο γράφος \en{G\_train}
χρησιμοποιείται για εξαγωγή  αναπαραστάσεων για εκπαίδευση και εύρεση βέλτιστων παραμέτρων.
Η λίστα \en{examples} με ετικέτες \en{labels} διαχωρίζεται περεταίρω σε 2 λίστες, 
\en{examples\_train, examples\_model\_selection} και \en{labels\_train, labels\_model\_selection}
αντίστοιχα, σε αναλογία \(75/25\). Η λίστα \en{examples\_train} μαζί με τις αντίστοιχες ετικέτες
\en{labels\_train} χρησιμοποιούνται για την εκπαίδευση των ταξινομητών κατά τη διαδικασία
εκπαίδευσης για την εύρεση βέλτιστων παραμέτρων, και το δεύτερο ζεύγος για την επιλογή του 
καλύτερου τελεστή. Η γενική λογική της διαδικασίας αυτής είναι να χρησιμοποιηθούν διαφορετικά
δεδομένα για κάθε στάδιο, αλλά η εύρεση των βέλτιστων τελεστών να γίνεται με τα ίδια 
δεδομένα, ώστε να είναι η διαδικασία κατά τα το δυνατό αντικειμενικότερη. Οι δύο πρώτοι
διαχωρισμοί έγιναν με τη συνάρτηση \en{stellargraph.data.EdgeSplitter.train\_test\_split}
ενώ το τελευταίος με τη συνάρτηση \en{sklearn.model\_selection.train\_test\_split} 
\cite{scikit-learn}.

\subsubsection{Εξαγωγή αναπαραστάσεων ακμών και επιλογή βέλτιστου τελεστή}

Η επόμενη διαδικασία αφορά την εύρεση του βέλτιστου τελεστή. Σε πρώτη φάση εξάγονται οι
αναπαραστάσεις των κόμβων από τον γράφο \en{G\_train}. Αρχικά, όπως περιγράφηκε σε προηγούμενο
κεφάλαιο, εξάγεται μια σειρά τυχαίων περιπάτων πάνω στο γράφο, με χρήση της συνάρτησης
\en{stellargaph.data.BiasedRandomWalk.run}. Αυτή η λίστα τυχαίων περιπάτων δίνεται ως είσοδος
στη συνάρτηση \en{gensim.models.Word2Vec} και επιστρέφεται τελικά η λίστα με τις αναπαραστάσεις
των κόμβων σε \(N\) διαστάσεις.

Στο σημείο αυτό εκτελείται η διαδικασία εύρεσης βέλτιστων παραμέτρων. Η διαδικασία αυτή επιχειρεί
να βρει τον βέλτιστο τελεστή εξαγωγής αναπαραστάσεων ακμών. Για τη διαδικασία αυτή 
χρησιμοποιούνται:

\begin{itemize}
    \item Η λίστα τελεστών: \begin{itemize}
        \item \en{Hadamard}
        \item \en{L1}
        \item \en{L2}
        \item \en{Mean}
    \end{itemize}
    \item Η λίστα \en{examples\_train} μαζί με τις ετικέτες \en{labels\_train} για την εκπαίδευση
    των ταξινομητών
    \item Οι αναπαραστάσεις των κόμβων
    \item Η λίστα \en{examples\_model\_selection} μαζί με τις ετικέτες
    \en{labels\_model\_selection} για την επικύρωση των ταξινομητών
\end{itemize}

Για κάθε τελεστή, εκτελείται μια μικρή διαδικασία πρόβλεψης συνδέσεων. Αρχικά σχηματίζονται 
οι αναπαραστάσεις των ακμών με χρήση του τελεστή, και εκπαιδεύεται ένας ταξινομητής 
Λογιστικής Παλινδρόμησης με χρήση Διασταυρωμένης Επικύρωσης. Ο ταξινομητής δημιουργείται με 
χρήση της \en{sklearn.linear\_model.LogisticRegressionCV} και εκπαιδεύεται με τα δεδομένα
\en{examples\_train, labels\_train}. Τέλος, ο ταξινομητής επικυρώνεται πάνω στα δεδομένα
\en{examples\_models\_selection, labels\_model\_selection} και εξάγεται η επίδοσή του 
με τις μετρικές \en{Accuracy, Precision, Recall, F1\_score, AUC\_score}. Ως βέλτιστος τελεστής επιλέγεται 
αυτός του οποίου ο ταξινομητής έχει το μέγιστο \en{AUC\_score}.

Στη συνέχεια, εξάγονται ξανά οι αναπαραστάσεις των κόμβων, με την ίδια διαδικασία, αυτή τη φορά
με χρήση του γράφου \en{G\_test}. Με χρήση του τελεστή με τα βέλτιστα αποτελέσματα σχηματίζονται
οι αναπαραστάσεις των ακμών, και στη συνέχεια εφαρμόζεται ο ταξινομητής που αντιστοιχεί στον 
εν λόγω τελεστή πάνω στα δεδομένα \en{examples\_test, labels\_test}. Η τελική απόδοση της 
τεχνικής συνοψίζεται σε 5 τελικές μετρικές, \en{Accuracy, Precision, Recall, F1\_score} και \en{AUC\_score}.

\subsection{Υλοποίηση με \en{CTDNE}}

Η δεύτερη υλοποίηση βασίστηκε πάνω στην πρώτη, ωστόσο υπάρχουν κάποιες διαφοροποιήσεις που θα
αναλυθούν στην παρούσα παράγραφο. 

\subsubsection{Εισαγωγή και διαχωρισμός δεδομένων}

Όπως διευκρινίστηκε σε προηγούμενη παράγραφο, η τεχνική εξαγωγής αναπαραστάσεων \en{CTDNE} 
απαιτεί χρονική πληροφορία της δημιουργίας των ακμών. Θεωρείται πως το βάρος της ακμής 
αντιστοιχεί στην χρονική στιγμή (\en{timestamp}) από τη στιγμή \en{epoch} που δημιουργήθηκε η
εν λόγω ακμή. Συνεπώς, κατά την εισαγωγή δεδομένων ως στήλη βαρών λαμβάνεται εκείνη που περιέχει
το \en{timestamp} της ακμής. Εάν αυτή δεν υπάρχει, τότε λαμβάνεται η στήλη με τα "κανονικά"
βάρη. Τέλος, αν δεν υπάρχει καθόλου στήλη βαρών των ακμών, τότε επιστρέφονται από την συνάρτηση
που εκτελεί τη διεργασία αυτή δύο μόνο στήλες, και στη συνέχεια ρυθμίζονται αυτόματα τα βάρη των
ακμών ίσα με τη μονάδα.

Ο διαχωρισμός των δεδομένων είναι πανομοιότυπος με την περίπτωση της \en{Node2Vec} υλοποίησης,
όπως περιγράφηκε στην Ενότητα \ref{n2v_data}.

\subsubsection{Εξαγωγή αναπαραστάσεων και επιλογή βέλτιστου τελεστή}

Η διαδικασία εύρεσης βέλτιστου τελεστή ξεκινάει με την δημιουργία τυχαίων περιπάτων, οι οποίοι
υπακούν στην αρχή της χρονικής συνέχειας. Όπως περιγράφηκε στην αντίστοιχη ενότητα, η αρχή
αυτή υποστηρίζει ότι κατά τη διάρκεια ενός περιπάτου, είναι δυνατή η μετάβαση σε επόμενο κόμβο
αν και μόνο αν η ακμή που συνδέει τον τρέχων με τον επόμενο κόμβο έχει δημιουργηθεί μεταγενέστερα
από την ακμή που συνδέει τον τρέχων με τον προηγούμενο κόμβο του περιπάτου. Για το σκοπό αυτό
η βιβλιοθήκη \en{Stellargraph} \cite{StellarGraph} παρέχει τη συνάρτηση 
\en{stellargraph.data.TemporalRandomWalk} που εξάγει τέτοιους περιπάτους από το γράφο. 
Στη συνέχεια οι περίπατοι αυτοί δίνονται σαν είσοδο στον αλγόριθμο \en{Word2Vec} και 
επιστρέφονται οι αναπαραστάσεις των κόμβων του γράφου \en{G\_train}.

\subsubsection{Εξαγωγή αναπαραστάσεων ακμών και επιλογή βέλτιστου τελεστή}

Η διαδικασία που ακολουθήθηκε στο στάδιο αυτό είναι πανομοιότυπη με την υλοποίηση με 
\en{Node2Vec}. Αξίζει να σημειωθεί πως μετά την ολοκλήρωση της επικύρωσης της τεχνικής,
διερευνάται και η περίπτωση χωρίς της χρονική παράμετρο στα δεδομένα. Επαναλαμβάνεται η 
διαδικασία δηλαδή, με τις βέλτιστες παραμέτρους και τα ίδια δεδομένα όπως ορίστηκαν για την
τεχνική \en{CTDNE}, με τη διαφορά πως στη στήλη των βαρών των ακμών, τα \en{timestamp}
έχουν αντικατασταθεί με τα "κανονικά" βάρη των ακμών, αν υπάρχουν, διαφορετικά με τη μονάδα.
Επίσης, η τεχνική εξαγωγής χαρακτηριστικών στην περίπτωση αυτή είναι η \en{Node2Vec}.

\subsection{Υλοποίηση με \en{GraphSage}}

Για την τρίτη και τελευταία υλοποίηση καταβλήθηκε προσπάθεια να είναι κατα το δυνατόν
όμοια με τις προηγούμενες, ωστόσο λόγω του σχεδιασμού των συναρτήσεων ήταν αναγκαίο να
διαφοροποιηθεί ελαφρώς. Επίσης έγιναν κάποιες απαραίτητες προσαρμογές στον αλγόριθμο
ώστε να ικανοποιούνται κάποιες απαιτήσεις για την ορθή λειτουργία του. Όλες οι αλλαγές
και οι τροποποιήσεις θα αναλυθούν στην παρούσα ενότητα.

\subsubsection{Εισαγωγή και διαχωρισμός δεδομένων}

Όπως αναφέρθηκε κατα τη θεωρητική ανάλυση, η τεχνική εξαγωγής αναπαραστάσεων \en{GraphSAGE}
απαιτεί την ύπαρξη χαρακτηριστικών κόμβων (\en{Node Features}). Για το λόγο αυτό,
απαιτείται τα δεδομένα προς εισαγωγή να συμπεριλαμβάνουν, σε ξεχωριστό αρχείο, τη λίστα
των χαρακτηριστικών για κάθε κόμβο. Η λίστα για ένα σύνολο \(N\) κόμβων με \(M\) πλήθος
χαρακτηριστικών είναι ένας \(N \times M\) πίνακας. Τα χαρακτηριστικά θα πρέπει να είναι σε
αριθμητική μορφή, δηλαδή κάθε στήλη πρέπει να αποτελείται μόνο από αριθμούς και όχι από κάτι
άλλο, όπως π.χ. αλφαριθμητικά δεδομένα. Συνεπώς, για τα δεδομένα που επρόκειτο να χρησιμοποιηθούν και
συγκεκριμένα για το σύνολο δεδομένων \en{CORA} που περιέχει χαρακτηριστικά κόμβων έγινε
προεπεξεργασία ώστε όλα τα χαρακτηριστικά να έχουν αριθμητική τιμή. Για τον αλγόριθμο δεν
έχει σημασία η απόλυτη τιμή ενός χαρακτηριστικού, αλλά η λειτουργία του βασίζεται στην
διαφορετικότητα των τιμών ανά τους κόμβους. Έτσι, για κάθε στήλη που αφορούσε χαρακτηριστικό
αλφαριθμητικού χαρακτήρα, για κάθε δυνατή διαφορετική τιμή δόθηκε μια ακέραια θετική 
αριθμητική τιμή. Επίσης, μετά την εισαγωγή τους στο πρόγραμμα τα χαρακτηριστικά υφίστανται 
περαιτέρω προεπεξεργασία. Αυτή περιλαμβάνει την ορθή αντιστοίχισή τους με τους κόμβους του γράφου,
αφαίρεση στηλών με ίδια ή μηδενική τιμή για όλους τους κόμβους, μιας και αυτές οι στήλες δεν 
προσφέρουν επιπλέον πληροφορία, παραμόνο επιβραδύνουν τη λειτουργία του προγράμματος και 
συμπλήρωση όλων των μη-διαθέσιμων τιμών (\en{N/A values}) (μτφ. Μη-Διαθέσιμες τιμές) 
με μηδενικά.

Για τα σύνολα δεδομένων που δεν εμπεριέχουν χαρακτηριστικά, τα τελευταία δημιουργούνται "τεχνητά".
Εφαρμόζεται η τεχνική εξαγωγής αναπαραστάσεων κόμβων \en{Node2Vec} στον γράφο και οι εξαγόμενες
αναπαραστάσεις χρησιμοποιούνται ώς χαρακτηριστικά. Αυτό όπως θα δούμε στη συνέχεια δεν προσφέρει
σημαντική βελτίωση στη λειτουργία του αλγορίθμου, μιας και αποτελεί μια κατα μία έννοια 
"διαφορετική" αναπαράσταση του ίδιου γράφου, χωρίς ωστόσο να προσφέρει κάποια περαιτέρω πληροφορία
για τα δεδομένα, όπως αναμένεται να κάνουν τα "κανονικά" χαρακτηριστικά. Τέλος, τα δεδομένα
διαχωρίστηκαν ακριβώς όπως και στις προηγούμενες υλοποιήσεις, δηλαδή αρχικά από έναν γράφο \en{G} 
σε ένα γράφο \en{G\_test} και οι λίστες \en{edges\_test, labels\_test} και μετά από τον
\en{G\_test} εξήχθησαν ο γράφος \en{G\_train} και οι λίστες \en{edges\_train, labels\_train}. 


\subsection{Εξαγωγή χαρακτηριστικών και εκπαίδευση ταξινομητή}

Για το στάδιο της εξαγωγής χαρακτηριστικών ακολουθήθηκε μια διαφορετική οδός, αφού κάτι τέτοιο
επέβαλλε ο σχεδιασμός των συναρτήσεων από τους δημιουργούς τους. Χρησιμοποιήθηκαν και πάλι 
συναρτήσεις της βιβλιοθήκης \en{StellarGraph} \cite{StellarGraph}. Στόχος είναι να χτιστεί ένα
μοντέλο της βιβλιοθήκης \en{keras} \cite{keras}, να εκπαιδευτεί πάνω στα κατάλληλα δεδομένα και
να επικυρωθεί.

Αρχικά, δημιουργήθηκαν γεννήτριες ακμών για την τροφοδοσία του μοντέλου με ακμές από τους γράφους
εκπαίδευσης και ελέγχου. Οι γεννήτριες ακμών ουσιαστικά χαρτογραφούν ζευγάρια κόμβων, δημιουργώντας
έτσι μια ακμή, και τις δίνουν σαν είσοδο στο μοντέλο \en{GraphSAGE}. Αυτή η λειτουργία 
επιτυγχάνεται με τον εξής τρόπο: οι γεννήτριες ακμών παίρνουν μικρές δέσμες  ζευγαριών κόμβων
και δειγματοληπτούν υπο-γράφους μέχρι και 2 βήματα μακριά. Αυτό σημαίνει πως για κάθε κόμβο
δειγματοληπτούνται όχι μόνο οι γείτονές του, δηλαδή όσοι κόμβοι έχουν άμεση σύνδεση με αυτόν, 
αλλά και οι γείτονες αυτών. Στη συνέχεια αυτοί οι γράφοι δίνονται σαν είσοδος στο μοντέλο, 
με κάθε ακμή να συνοδεύεται και από μία δυαδική μεταβλητή που επισημαίνει αν πρόκειται για
αληθή ή ψευδή ακμή. Δημιουργούνται δύο γεννήτριες, μία για τον γράφο εκπαίδευσης και μία για τον 
γράφο ελέγχου. Για τη λειτουργία αυτή, χρησιμοποιείται η συνάρτηση
\en{stellargraph.mapper.GraphSAGELinkGenerator} για τη δημιουργία της γεννήτριας και για την
πρόσβαση στα ζευγάρια κόμβων χρησιμοποιείται η συνάρτηση του αντικειμένου της γεννήτριας
\en{stellargraph.mapper.GraphSAGELinkGenerator.flow()}.

Στη συνέχεια χτίζεται το μοντέλο. Υλοποιήθηκε ένα μοντέλο \en{GraphSAGE} δύο στρωμάτων, όπου το
πρώτο χρησιμοποιείται για την εκμάθηση αναπαραστάσεων κόμβων, και το δεύτερο για ταξινόμηση ακμών
που λειτουργεί με τις αναπαραστάσεις που δημιουργήθηκαν στο πρώτο στρώμα. Το πρώτο στρώμα
δημιουργείται με τη συνάρτηση \en{stellargraph.layer.GraphSAGE}. Για την εκπαίδευση του
χρησιμοποιείται ο γράφος εκπαίδευσης. Το δεύτερο στρώμα όπως αναφέρθηκε υλοποιεί τον ταξινομητή 
των ακμών. Ουσιαστικά παίρνει σαν είσοδο τις αναπαραστάσεις για ένα ζεύγος κόμβων, όπως αυτό 
δημιουργήθηκε στο προηγούμενο στρώμα, και εφαρμόζει έναν τελεστή για τη δημιουργία της 
αναπαράστασης της ακμής. Έπειτα η αναπαράσταση αυτή δίνεται σαν είσοδος στον ταξινομητή και 
στην έξοδο του στρώματος βγαίνει η "πρόβλεψη" για το αν η ακμή είναι αληθής ή όχι. Για τη 
δημιουργία του στρώματος αυτού χρησιμοποιείται η συνάρτηση  
\en{stellargraph.layer.link\_classification}. Έπειτα τα δύο αυτά στρώματα συγκεντρώνονται για τη 
δημιουργία του τελικού μοντέλου \en{keras} \cite{keras} και διευκρινίζονται οι μετρικές
επίδοσης που πρόκειται να χρησιμοποιηθούν, με χρήση της συνάρτησης 
\en{tensorflow.keras.Model} και \en{tensorflow.keras.Model.compile}.

Αφού επικυρωθεί το μοντέλο πριν την τελική εκπαίδευση για σύγκριση, ξεκινάει η εκπαίδευση με
δεδομένα εκπαίδευσης τον γράφο εκπαίδευσης και δεδομένα επαλήθευσης τον γράφο ελέγχου. Τελικά
λαμβάνονται οι μετρικές επίδοσης για το εκπαιδευμένο πλέον μοντέλο.